java -cp com.sinolink.dw.filepublisher-1.0-SNAPSHOT.jar com.sinolink.dw.filepublisher.KafkaFileReceiver --kafka.group.id=r2
java -cp com.sinolink.dw.filepublisher-1.0-SNAPSHOT.jar com.sinolink.dw.filepublisher.FileTaskMain --kafka.group.id=r2


bin/kafka-topics.sh --list --zookeeper localhost:2181

bin/kafka-topics.sh --delete --zookeeper localhost:2181 --topic test
rm -rf /tmp/kafka-logs/test-*

./kafka-server-stop.sh ../config/server.properties
./kafka-server-start.sh -daemon ../config/server.properties

bin/kafka-topics.sh --delete --zookeeper localhost:2181 --topic test2
bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 4 --topic test2


bin/kafka-console-producer.sh --broker-list localhost:9092 --topic prod_doc
bin/kafka-console-consumer.sh --zookeeper localhost:2181 --topic test2 --from-beginning
bin/kafka-topics.sh --describe --zookeeper localhost:2181 --topic prod_doc_received

bin/kafka-run-class.sh kafka.tools.ConsumerOffsetChecker --zookeeper localhost:2181 --group c9
bin/kafka-run-class.sh kafka.tools.UpdateOffsetsInZK earliest config/consumer.properties prod_doc
[earliest | latest]，表示将offset置到哪里
consumer.properties ，这里是配置文件的路径
topic，topic名，这里是prod_doc


#注意:  默认情况下producer和consumer都需要能访问以hostname所标识的broker所在机器,
但可以通过设置broker的advertised.host.name设置项来改变这个行为,当要保证设置的值,broker.producer和consumer所在机器都能访问,比如通过修改hosts文件或搭建DNS服务


#消息体size相关设置  fetch.message.max.bytes >= replica.fetch.max.bytes >= message.max.bytes
Broker Configs($KAFKA_HOME/config/server.properties)
fetch.message.max.bytes
replica.fetch.max.bytes
message.max.bytes: broker可以接收的message的最大size

Consumer Configs($KAFKA_HOME/config/consumer.properties)
fetch.message.max.bytes(默认1M): 针对一个partition,consumer获取到的单个消息的最大size
consumer从kafka fetch数据，也是批量fetch的，虽然你处理的时候是onebyone逻辑，但后台是预读的
这个值至少要等于broker里面设置的maximum message size，否则有可能连一条message都取不下来
默认是1m，设太大会爆内存，而且会增大读重的可能性，因为当consumer发生变化时，会发生rebalance，这时被新分配到这个partition的consumer仍然会读到预读但没有commit的数据

queued.max.message.chunks(默认10):可以同时读取多少个块,该值至少大于consumer连接的partition个数,以进行并发读取,但每个块的大小不会大于fetch.message.max.bytes指定的值


防止consumer crash丢失数据，可以在确认数据被正确处理后，再手工commit offset

macox protobuffer:
brew install automake
chown -R fj /usr/local/share/info
brew link autoconf

brew install libtool
sudo chown -R fj /usr/local/include/
sudo chown -R fj /usr/local/lib/
brew link libtool

chown -R root /usr/local/share/info
sudo chown -R root /usr/local/include/
sudo chown -R root /usr/local/lib/

